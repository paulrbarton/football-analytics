name: Scrape Understat xG Data (API)

on:
  # Manual trigger with inputs
  workflow_dispatch:
    inputs:
      teams:
        description: 'Team name (e.g., "Nottingham Forest") or "all" for all teams'
        required: false
        default: 'all'
        type: string
      season:
        description: 'Season year (e.g., "2024" for 2024-25 season)'
        required: false
        default: '2024'
        type: string
  
  # Scheduled run (daily at 8 AM UTC)
  schedule:
    - cron: '0 8 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r data_collection/requirements.txt
      
      - name: Set environment variables
        run: |
          echo "DATA_DESTINATION=motherduck" >> $GITHUB_ENV
          echo "DATABASE_NAME=football_analytics" >> $GITHUB_ENV
          echo "SCHEMA_NAME=raw" >> $GITHUB_ENV
          echo "SEASON=${{ github.event.inputs.season || '2024' }}" >> $GITHUB_ENV
          echo "DUCKDB_MOTHERDUCK_DISABLE_SSL_VERIFICATION=1" >> $GITHUB_ENV
        
      - name: Scrape Understat data (single team)
        if: github.event.inputs.teams != 'all' && github.event.inputs.teams != ''
        env:
          MOTHERDUCK_TOKEN: ${{ secrets.MOTHERDUCK_TOKEN }}
        run: |
          cd data_collection/scrapers
          python understat_api_scraper.py
      
      - name: Scrape Understat data (all teams)
        if: github.event.inputs.teams == 'all' || github.event.inputs.teams == ''
        env:
          MOTHERDUCK_TOKEN: ${{ secrets.MOTHERDUCK_TOKEN }}
        run: |
          cd data_collection/scrapers
          python -c "
          import asyncio
          import sys
          import os
          sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
          from understat_api_scraper import UnderstatAPIScraper, save_data
          
          async def scrape_all():
              scraper = UnderstatAPIScraper()
              try:
                  season = os.getenv('SEASON', '2024')
                  destination = os.getenv('DATA_DESTINATION', 'local')
                  database = os.getenv('DATABASE_NAME', 'football_analytics')
                  schema = os.getenv('SCHEMA_NAME', 'raw')
                  
                  print(f'Scraping all teams for season {season}...')
                  df = await scraper.get_all_teams_data(season)
                  
                  if not df.empty:
                      save_data(
                          df,
                          f'understat_api_premier_league_{season}',
                          destination=destination,
                          database=database,
                          schema=schema,
                          if_exists='replace'
                      )
                      print(f'✓ Successfully scraped {len(df)} matches')
                  else:
                      print('⚠ No data retrieved')
              finally:
                  await scraper.close()
          
          asyncio.run(scrape_all())
          "
      
      - name: Upload data artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: understat-data-${{ github.run_number }}
          path: |
            data/raw/understat_api_*.csv
            data/export/understat_api_*.parquet
          retention-days: 7
